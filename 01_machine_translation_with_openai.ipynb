{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoint\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(prompt, text, url, model, headers):\n",
    "\n",
    "    # Request headers\n",
    "    headers = headers\n",
    "    # Request data\n",
    "    data = {\n",
    "        # 'prompt': prompt,\n",
    "        # 'max_tokens': 15000,  # Maximum number of tokens (words) to generate\n",
    "        'model': model,\n",
    "        'messages': [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Making the API request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        translated_text = response.json()['choices'][0]['message']['content']\n",
    "    else:\n",
    "        # Print error message\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of prompts\n",
    "\n",
    "prompt1 = 'You are an expert translator. Translate the following text to Russian using vocabulary and expressions of a Russian native. The text to be translated is:'\n",
    "prompt2 = 'You are an expert translator that will be tasked with translating a piece of text into Russian. The translation must be faithful to the original tone of voice and writing style. Ensure that the meaning of the original text is not changed. The text to be translated is:'\n",
    "prompts = [prompt1, prompt2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['literature' 'medical' 'law']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>title</th>\n",
       "      <th>en_text</th>\n",
       "      <th>ru_human_translation</th>\n",
       "      <th>en_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>literature</td>\n",
       "      <td>Of Human Bondage by Somerset Maugham</td>\n",
       "      <td>The day broke gray and dull. The clouds hung h...</td>\n",
       "      <td>День занялся тусклый, серый. Тучи повисли низк...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>literature</td>\n",
       "      <td>A Tale of Two Cities by Charles Dickens</td>\n",
       "      <td>It was the best of times, it was the worst of ...</td>\n",
       "      <td>Это было лучшее из всех времен, это было худш...</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medical</td>\n",
       "      <td>Barnard C.N. The operation. A human cardiac tr...</td>\n",
       "      <td>POSTOPERATIVE CARE. The postoperative care of ...</td>\n",
       "      <td>Послеоперационное ведение. Послеоперационное в...</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medical</td>\n",
       "      <td>Guidelines on diabetes, pre-diabetes, and card...</td>\n",
       "      <td>Definition and classification of diabetes. Cri...</td>\n",
       "      <td>Определение и классификация диабета. Критерии ...</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>law</td>\n",
       "      <td>CODE OF CONDUCT FOR EUROPEAN LAWYERS</td>\n",
       "      <td>1. PREAMBLE. 1.1. The Function of the Lawyer i...</td>\n",
       "      <td>I. Преамбула. 1.1. Функция адвоката в обществе...</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>law</td>\n",
       "      <td>The Indian Contract Act (ICA), 1872</td>\n",
       "      <td>Preamble. WHEREAS it is expedient to define an...</td>\n",
       "      <td>Преамбула. Принимая во внимание целесообразнос...</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        field                                              title  \\\n",
       "0  literature               Of Human Bondage by Somerset Maugham   \n",
       "1  literature            A Tale of Two Cities by Charles Dickens   \n",
       "2     medical  Barnard C.N. The operation. A human cardiac tr...   \n",
       "3     medical  Guidelines on diabetes, pre-diabetes, and card...   \n",
       "4         law               CODE OF CONDUCT FOR EUROPEAN LAWYERS   \n",
       "5         law                The Indian Contract Act (ICA), 1872   \n",
       "\n",
       "                                             en_text  \\\n",
       "0  The day broke gray and dull. The clouds hung h...   \n",
       "1  It was the best of times, it was the worst of ...   \n",
       "2  POSTOPERATIVE CARE. The postoperative care of ...   \n",
       "3  Definition and classification of diabetes. Cri...   \n",
       "4  1. PREAMBLE. 1.1. The Function of the Lawyer i...   \n",
       "5  Preamble. WHEREAS it is expedient to define an...   \n",
       "\n",
       "                                ru_human_translation  en_length  \n",
       "0  День занялся тусклый, серый. Тучи повисли низк...        497  \n",
       "1   Это было лучшее из всех времен, это было худш...        486  \n",
       "2  Послеоперационное ведение. Послеоперационное в...        484  \n",
       "3  Определение и классификация диабета. Критерии ...        494  \n",
       "4  I. Преамбула. 1.1. Функция адвоката в обществе...        499  \n",
       "5  Преамбула. Принимая во внимание целесообразнос...        448  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading a dataset of English texts and their human translations from various fields\n",
    "\n",
    "df = pd.read_json('texts.json')\n",
    "print(df.field.unique())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a list of (field, title, en text, human translation, prompt) tuples\n",
    "\n",
    "texts = list(df.en_text)\n",
    "fields = list(df.field)\n",
    "titles = list(df.title)\n",
    "human_ru = list(df.ru_human_translation)\n",
    "prompt_texts = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    item = [(field, title, prompt, text, human) for field, title, text, human in zip(fields, titles, texts, human_ru)]\n",
    "    prompt_texts.extend(item)\n",
    "\n",
    "len(prompt_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sending (prompt, text) pairs to the API and collecting translated results by adding it to the list of tuples\n",
    "\n",
    "prompt_text_translations = []\n",
    "\n",
    "for item in prompt_texts:\n",
    "    translation = translate(item[2], item[3], url, model, headers)\n",
    "    new_item = (*item, translation)\n",
    "    prompt_text_translations.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe with the results, tokenizing the data with sent_tokenize\n",
    "\n",
    "df2 = pd.DataFrame(prompt_text_translations, columns=['field', 'title', \n",
    "                    'prompt', 'en_text', 'ru_human_translation', 'ru_machine_translation'])\n",
    "\n",
    "df2['en_text'] = df2['en_text'].apply(sent_tokenize)\n",
    "df2['ru_human_translation'] = df2['ru_human_translation'].apply(sent_tokenize)\n",
    "df2['ru_machine_translation'] = df2['ru_machine_translation'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(list1, list2):\n",
    "    '''in case the human and machine translations vary in sentence counts, \n",
    "    this function adds '' paddings to the shorter translation \n",
    "    so that their lengths match (required for evaluation)'''\n",
    "    len1 = len(list1)\n",
    "    len2 = len(list2)\n",
    "    if len1 > len2:\n",
    "        num_pad = len1-len2\n",
    "        paddings = ['' for x in range(num_pad)]\n",
    "        list2.extend(paddings)\n",
    "    elif len2 > len1:\n",
    "        num_pad = len2-len1\n",
    "        paddings = ['' for x in range(num_pad)]\n",
    "        list1.extend(paddings)\n",
    "    return(list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df2.iterrows():\n",
    "    padded_human, padded_machine = add_padding(row['ru_human_translation'], row['ru_machine_translation'])\n",
    "    row['ru_human_translation'] = padded_human\n",
    "    row['ru_machine_translation'] = padded_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary from the dataframe to store as .json\n",
    "\n",
    "reference_candidate_dict = {}\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    label = row['field']\n",
    "    prompt = row['prompt']\n",
    "    source = row['en_text']\n",
    "    machine_translation = row['ru_machine_translation']\n",
    "    human_translation = row['ru_human_translation']\n",
    "    \n",
    "    if label in reference_candidate_dict:\n",
    "        if prompt in reference_candidate_dict[label]:\n",
    "            reference_candidate_dict[label][prompt].append((source, machine_translation, human_translation))\n",
    "        else:\n",
    "            reference_candidate_dict[label][prompt] = [(source, machine_translation, human_translation)]\n",
    "    else:\n",
    "        reference_candidate_dict[label] = {prompt: [(source, machine_translation, human_translation)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved as 'mt_for_eval.json'\n"
     ]
    }
   ],
   "source": [
    "file_path = 'mt_for_eval.json'\n",
    "\n",
    "# Save the dictionary as a .json file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(reference_candidate_dict, json_file, indent=4)\n",
    "\n",
    "print(f\"Dictionary saved as '{file_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
